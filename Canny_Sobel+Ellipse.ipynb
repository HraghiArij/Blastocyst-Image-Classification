{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UcDwb7spotK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpKaq3lor4TD",
        "outputId": "0162acc9-1106-418b-c968-78c10f5f5775"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5YR2Ot-prf5"
      },
      "outputs": [],
      "source": [
        "def create_dir(path):\n",
        "    \"\"\"Create a directory\"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icxoSoidnn9u"
      },
      "source": [
        "## SOBEL + CROP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZhLhtBLdQxT"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Initialize the threshold value\n",
        "threshold_value = 30\n",
        "\n",
        "while True:\n",
        "\n",
        "        sobel_x = cv2.Sobel(grayscale_image, cv2.CV_64F, 1, 0, ksize=3)\n",
        "        sobel_y = cv2.Sobel(grayscale_image, cv2.CV_64F, 0, 1, ksize=3)\n",
        "        edge_image = np.sqrt(sobel_x**2 + sobel_y**2)\n",
        "\n",
        "\n",
        "        edge_mask = (edge_image > threshold_value).astype(np.uint8)\n",
        "\n",
        "        # Find contours\n",
        "        contours, _ = cv2.findContours(edge_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        if contours:\n",
        "            break\n",
        "\n",
        "\n",
        "        threshold_value -= 5\n",
        "\n",
        "# Find the bounding box of the largest contour\n",
        "largest_contour = max(contours, key=cv2.contourArea)\n",
        "x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "\n",
        "\n",
        "mask = np.zeros_like(image)\n",
        "\n",
        "# Draw the largest contour on the mask\n",
        "cv2.drawContours(mask, [largest_contour], -1, (0, 255, 0), thickness=cv2.FILLED)\n",
        "\n",
        "\n",
        "# Crop the original image using the bounding box\n",
        "cropped_image = image[y:y+h, x:x+w]\n",
        "\n",
        "print(image_path + \" done\")\n",
        "plt.imshow(cropped_image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjosZffynn9x"
      },
      "source": [
        "## SOBEL + ELLIPSE + CROP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jytScdJLQrxJ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def CropEllipse(image_path):\n",
        "  # Load the image\n",
        "  #image_path = r\"C:\\Users\\miste\\Desktop\\Projet Aziza Othmana\\DATASETS\\BLASTOCYST_ main\\blastocyst_main\\Images\\0001_01.png\"\n",
        "  image = cv2.imread(image_path)\n",
        "\n",
        "\n",
        "  grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  sobel_x = cv2.Sobel(grayscale_image, cv2.CV_64F, 2, 1, ksize=5)\n",
        "  sobel_y = cv2.Sobel(grayscale_image, cv2.CV_64F, 1, 2, ksize=5)\n",
        "  edge_image = np.sqrt(sobel_x ** 2 + sobel_y ** 2)\n",
        "\n",
        "\n",
        "  threshold_value = 30\n",
        "  edge_mask = (edge_image > threshold_value).astype(np.uint8)\n",
        "\n",
        "\n",
        "  contours, _ = cv2.findContours(edge_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "  largest_contour = max(contours, key=cv2.contourArea)\n",
        "  x1, y1, w1, h1 = cv2.boundingRect(largest_contour)\n",
        "\n",
        "\n",
        "  mask = np.zeros_like(image)\n",
        "\n",
        "  cv2.drawContours(mask, [largest_contour], -1, (0, 255, 0), thickness=cv2.FILLED)\n",
        "\n",
        "  plt.imshow(cv2.cvtColor(mask, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  # Parameters for ellipse creation\n",
        "  p = x1 + w1 // 2  # X-coordinate of ellipse center\n",
        "  k = y1 + h1 // 2  # Y-coordinate of ellipse center\n",
        "  alpha =0          # Angle in degrees\n",
        "  a = w1 // 2       # Semi-major axis length\n",
        "  b = h1 // 2       # Semi-minor axis length\n",
        "\n",
        "\n",
        "  segmentation_mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
        "\n",
        "\n",
        "  for y in range(image.shape[0]):\n",
        "      for x in range(image.shape[1]):\n",
        "          # The ellipse equation\n",
        "          term1 = ((x - p) * np.cos(np.radians(alpha)) + (y - k) * np.sin(np.radians(alpha))) ** 2\n",
        "          term2 = a ** 2\n",
        "          term3 = ((x - p) * np.sin(np.radians(alpha)) - (y - k) * np.cos(np.radians(alpha))) ** 2\n",
        "          term4 = b ** 2\n",
        "          value = term1 / term2 + term3 / term4\n",
        "\n",
        "          # Check if the pixel falls within the ellipse\n",
        "          if value <= 1:\n",
        "              # Set the pixel to white\n",
        "              segmentation_mask[y, x] = 255\n",
        "\n",
        "\n",
        "  result_image = cv2.bitwise_and(image, image, mask=segmentation_mask)\n",
        "\n",
        "\n",
        "  cropped_image = result_image[y1:y1+h1\n",
        "                              , x1:x1+w1]\n",
        "\n",
        "\n",
        "  resized_cropped_image = cv2.resize(cropped_image, (299, 299), interpolation=cv2.INTER_NEAREST)\n",
        "  return cropped_image\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "sav_path = \"/content/drive/MyDrive/Cropped_images_AZIZAOTHMANA_Ellipse\"\n",
        "base_dir=\"/content/drive/MyDrive/DatasetAzizaOthmana/Images\"\n",
        "img=\"MTL-0130-0FD2-AB62-[47]-P03-FP3.jpg\"\n",
        "#for img in os.listdir(base_dir):\n",
        "image_path = os.path.join(base_dir, img)\n",
        "cropped_image=CropEllipse(image_path)\n",
        "print(img + \" done\")\n",
        "cv2_imshow(cropped_image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "    #cv2.imwrite(os.path.join(sav_path, img), cropped_image)\n",
        "\n",
        "\n",
        "\n",
        "# Close any open plot window (if you're using plt for visualization)\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "VGPx3Hlbv8hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEiQ4MIenn90"
      },
      "source": [
        "DELETE FILES FROM DIRECTORY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cup4dDyByWvn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/Images-azizaothmmana/Cropped_images\"\n",
        "\n",
        "# Get a list of all files in the folder\n",
        "files = os.listdir(folder_path)\n",
        "\n",
        "# Loop through the list of files and delete each one\n",
        "for file in files:\n",
        "    file_path = os.path.join(folder_path, file)\n",
        "    try:\n",
        "        if os.path.isfile(file_path):\n",
        "            os.remove(file_path)\n",
        "            print(f\"Deleted: {file_path}\")\n",
        "        else:\n",
        "            print(f\"Not a file: {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error deleting {file_path}: {e}\")\n",
        "\n",
        "print(\"All files in the folder have been deleted.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG6qAa9snn90"
      },
      "source": [
        "#  CANNY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY1IgfkCUSoM"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the image\n",
        "#image_path = \"\" #add the path\n",
        "def Canny(image_path):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    blurred_image = cv2.GaussianBlur(gray_image, (3, 3), 0)\n",
        "    edges = cv2.Canny(blurred_image, threshold1=50, threshold2=20)\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    dilated_edges = cv2.dilate(edges, kernel, iterations=1)\n",
        "    contours, _ = cv2.findContours(dilated_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    largest_contour = max(contours, key=cv2.contourArea)\n",
        "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "    mask = np.zeros_like(image)\n",
        "    cv2.drawContours(mask, [largest_contour], -1, (0, 255, 0), thickness=cv2.FILLED)\n",
        "    cropped_image = image[y:y+h, x:x+w]\n",
        "    enhanced_image = cv2.resize(crop_image, (299, 299))\n",
        "    #plt.imshow(cv2.cvtColor(dilated_edges, cv2.COLOR_BGR2RGB))\n",
        "    return cropped_image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRCqbV6knn91"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "#There will be no output due to data confidentiality\n",
        "sav_path = \"/content/drive/MyDrive/Cropped_Image_Canny\"\n",
        "base_dir=\"/content/drive/MyDrive/DatasetAzizaOthmana/Images\"\n",
        "for img in os.listdir(base_dir):\n",
        "    image_path = os.path.join(base_dir, img)\n",
        "    cropped_image=Canny(image_path)\n",
        "    print(img + \" done\")\n",
        "    cv2_imshow(cropped_image)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "    cv2.imwrite(os.path.join(sav_path, img), cropped_image)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Contrast Enhancement"
      ],
      "metadata": {
        "id": "BxlgeClFCO-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the image\n",
        "image_path =\"\" #add the path\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Apply contrast enhancement using CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(1, 1))\n",
        "enhanced_image = np.zeros_like(image)\n",
        "\n",
        "for channel in range(3):  # Assuming a BGR color image\n",
        "    enhanced_image[:, :, channel] = clahe.apply(image[:, :, channel])\n",
        "\n",
        "cv2.imwrite('enhanced_image.jpg', enhanced_image)\n",
        "\n",
        "\n",
        "cv2_imshow(image)\n",
        "cv2_imshow(enhanced_image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yuA2J6Ha8OWh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}